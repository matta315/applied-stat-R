---
title: "Untitled"
author: "Anh Nguyen"
date: "8/4/2020"
output: html_document
---

```{r results=FALSE}
library(faraway)
library(knitr)
library(dplyr)
library(ggplot2)

```
# Team

# Introduction

As both member in our team are residents in King County, WA, housing is one of topics we are both interested in. In the last couple years, housing market in WA has remaining hot. We want to use this exercise to understand the pricing indicators of King county's WA, what aspect would affect housing price the most, which zipcode is most affordable and might be interest in having a model to predict housing price for the future.

## About the data


```{r}
data = read.csv("kc_house_data.csv")
month = as.factor(substr(data$date, 5, 6))
age = as.integer(substr(data$date, 1, 4)) - ifelse(data$yr_renovated == 0, as.integer(data$yr_built), as.integer(data$yr_renovated))
data = subset(data, select = -c(id, lat, long, date, yr_built, yr_renovated))
data = cbind(data, month, age)
data$waterfront = as.factor(data$waterfront)
data$view = as.factor(data$view)
data$condition = as.factor(data$condition)
data$grade = as.factor(data$grade)
data$floors = as.factor(data$floors)
data$bedrooms = as.factor(data$bedrooms)
data$bathrooms = as.factor(data$bathrooms)
data$zipcode = as.factor(data$zipcode)
head(data)
```

This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.

https://www.kaggle.com/harlfoxem/housesalesprediction?select=kc_house_data.csv

This file is containing `r nrow(data)` observations of residential houses sold in 2014 - 2014. We are looking to construct a model help predicting house price using available variable as:

- Id
- Date
- Price
- Bedrooms
- Bathrooms
- Sqft_living
- Sqft_lot
- Floors
- Waterfront
- View
- Condition
- Grade
- Sqft_above
- Sqft_basement
- Yr_built
- Yr_renovated
- Zipcode
- Lat
- Long
- Sqft_living15
- Sqft_lot15


```{r}
kable(head(data,20))
```

# Method
## Data Cleaning


## Exploratory Analysis


(1) Checking **Colinerity**

```{r}
pairs(data)

```


(2) Slitting data to train/test

```{r}
data = na.omit(data)
set.seed(20200804)
trn_idx = sample(nrow(data), 5000)
data_trn = data[trn_idx, ]
data_tst = data[-trn_idx, ]
```

(3) Helping functions

```{r, message = FALSE, warning = FALSE}
library(lmtest)

get_bp_decision = function(model, alpha) {
  decide = unname(bptest(model)$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_sw_decision = function(model, alpha) {
  decide = unname(shapiro.test(resid(model))$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

```


## Model Selection
### Model Generating/ Initial Model

1. Model with Linear Relationship

```{r}
#add_mod = lm (log(price) ~ bedrooms + bathrooms + sqft_above +	sqft_basement + zipcode + sqft_living15 +	sqft_lot15+ month + age , data = data_trn)

add_mod = lm (log(price) ~ sqft_above +	sqft_basement + I(sqft_above^2), data = data_trn)

#add_mod = lm (log(price) ~ grade + log(sqft_living) + zipcode + bathrooms +	log(sqft_living15) , data = data_trn)
```

```{r, echo=FALSE, results='hide'}

n = length(resid(add_mod))

add_both_aic = step(add_mod, direction = "both", trace = FALSE)
add_back_aic = step(add_mod, direction = "backward", trace = FALSE)
add_fwrd_aic = step(add_mod, direction = "forward", trace = FALSE)
add_both_bic = step(add_mod, direction = "both", k = log(n), trace = FALSE)
#names(coef(add_both_bic))
add_back_bic = step(add_mod, direction = "forward", k = log(n), trace = FALSE)
add_fwrd_bic = step(add_mod, direction = "backward", k = log(n), trace = FALSE)
```

Validating different initial models

```{r}
alpha = 0.05

add_adj_r_2 = c(get_adj_r2(add_both_aic),
            get_adj_r2(add_both_bic),
            get_adj_r2(add_back_aic),
            get_adj_r2(add_back_bic),
            get_adj_r2(add_fwrd_aic),
            get_adj_r2(add_fwrd_bic)
)

add_bp_decision = c(get_bp_decision(add_both_aic, alpha),
                get_bp_decision(add_both_bic, alpha),
                get_bp_decision(add_back_aic, alpha),
                get_bp_decision(add_back_aic, alpha),
                get_bp_decision(add_fwrd_aic, alpha),
                get_bp_decision(add_fwrd_bic, alpha)
                )

add_sw_decision = c(get_sw_decision(add_both_aic, alpha),
                get_sw_decision(add_both_bic, alpha),
                get_sw_decision(add_back_aic, alpha),
                get_sw_decision(add_back_bic, alpha),
                get_sw_decision(add_fwrd_aic, alpha),
                get_sw_decision(add_fwrd_bic, alpha)
                )

add_loove_rmse = c(get_loocv_rmse(add_both_aic),
               get_loocv_rmse(add_both_bic),
               get_loocv_rmse(add_back_aic),
               get_loocv_rmse(add_back_bic),
               get_loocv_rmse(add_fwrd_aic),
               get_loocv_rmse(add_fwrd_bic)
               )

add_parameter = c(get_num_params(add_both_aic),
              get_num_params(add_both_bic),
              get_num_params(add_back_aic),
              get_num_params(add_back_bic),
              get_num_params(add_fwrd_aic),
              get_num_params(add_fwrd_bic)
              )

result_add = data.frame(add_adj_r_2, add_loove_rmse, add_bp_decision, add_sw_decision, add_parameter)
row.names(result_add) = c("both_AIC", "both_BIC", "back_AIC", "back_BIC", "fwrd_AIC", "fwrd_BIC")
kable(result_add, 
      col.names = c("adj_R_2","RMSE (LOOCV)", "Constant Var Tesr", "Normality Test", "Parameter")
  )

```

2. Model with Quadratic Relationship

```{r}
int_mod = lm(log(price) ~ (sqft_above +	sqft_basement + zipcode)^2, data = data_trn)
```

```{r, echo=FALSE, results='hide'}

n = length(resid(int_mod))

int_both_aic = step(int_mod, direction = "both", trace = FALSE)
int_back_aic = step(int_mod, direction = "backward", trace = FALSE)
int_fwrd_aic = step(int_mod, direction = "forward", trace = FALSE)
int_both_bic = step(int_mod, direction = "both", k = log(n), trace = FALSE)
int_back_bic = step(int_mod, direction = "forward", k = log(n), trace = FALSE)
int_fwrd_bic = step(int_mod, direction = "backward", k = log(n), trace = FALSE)
```

```{r}
alpha = 0.05

int_adj_r_2 = c(get_adj_r2(int_both_aic),
            get_adj_r2(int_both_bic),
            get_adj_r2(int_back_aic),
            get_adj_r2(int_back_bic),
            get_adj_r2(int_fwrd_aic),
            get_adj_r2(int_fwrd_bic)
)

int_bp_decision = c(get_bp_decision(int_both_aic, alpha),
                get_bp_decision(int_both_bic, alpha),
                get_bp_decision(int_back_aic, alpha),
                get_bp_decision(int_back_aic, alpha),
                get_bp_decision(int_fwrd_aic, alpha),
                get_bp_decision(int_fwrd_bic, alpha)
                )

int_sw_decision = c(get_sw_decision(int_both_aic, alpha),
                get_sw_decision(int_both_bic, alpha),
                get_sw_decision(int_back_aic, alpha),
                get_sw_decision(int_back_bic, alpha),
                get_sw_decision(int_fwrd_aic, alpha),
                get_sw_decision(int_fwrd_bic, alpha)
                )

int_loove_rmse = c(get_loocv_rmse(int_both_aic),
               get_loocv_rmse(int_both_bic),
               get_loocv_rmse(int_back_aic),
               get_loocv_rmse(int_back_bic),
               get_loocv_rmse(int_fwrd_aic),
               get_loocv_rmse(int_fwrd_bic)
               )

int_parameter = c(get_num_params(int_both_aic),
              get_num_params(int_both_bic),
              get_num_params(int_back_aic),
              get_num_params(int_back_bic),
              get_num_params(int_fwrd_aic),
              get_num_params(int_fwrd_bic)
              )

result_int = data.frame(int_adj_r_2, int_loove_rmse, int_bp_decision, int_sw_decision, int_parameter)
row.names(result_int) = c("both_AIC", "both_BIC", "back_AIC", "back_BIC", "fwrd_AIC", "fwrd_BIC")
kable(result_int,
      col.names = c( "adj_R_2","RMSE (LOOCV)", "Constant Var Tesr", "Normality Test", "Parameter")
  )
```


After running some initial test we decided to pick 2 model

```{r}
model_1 = add_both_bic
model_2 = int_both_aic
```

### Model Improvement 

Help function
```{r, echo=FALSE}
#leverage point
get_high_lev_points = function(model){
  length(hatvalues(model)[hatvalues(model) > 2 * mean(hatvalues(model))])
}

#outliner
get_outliners = function(model){
  length(rstandard(model)[abs(rstandard(model)) > 2])
}

#Influence
get_influence = function(model){
  length(cooks.distance(model)[cooks.distance(model) > 4 / length(cooks.distance(model))])
}

#drawing plot
draw_graph = function (model, pcol = "gray", lcol = "dodgerblue") {
    par(mfrow = c(1,2))
    #fitted vs residual plots
    plot(fitted(model), resid(model), col = "grey", pch = 20,
      xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual Graph")
      abline(h = 0, col = "darkorange", lwd = 2)
      
    #QQ Plot 
    qqnorm(resid(model), main = "Normal Q-Q Plot, fit_1", col = pcol)
    qqline(resid(model), col = lcol, lwd = 2)
}

#New data set for removal method
get_new_data = function(model){
  outliner = as.vector(as.integer(names(rstandard(model)[abs(rstandard(model)) > 2])))
  high_influence = as.vector(which(cooks.distance(model)> 4/ length(cooks.distance(model))))
  tobeRemove = c(outliner,high_influence)
  new_data = data[-toBeRemove,]
  new_data
}
```

Checking Ourliner/influencers

1. Additive Model

```{r}
names(coef(model_1))
```

Number of high leverage point is `r get_high_lev_points(model_1)`

Number of outliners is `r get_outliners(model_1)`

Number of influence points `r get_influence(model_1)`

Plots for model 1

```{r}
draw_graph(model_1)
```


2. Interactive Model
```{r}
names(coef(model_2))
```


Number of high leverage point is `r get_high_lev_points(model_2)`

Number of outliners is `r get_outliners(model_2)`

Number of influence points `r get_influence(model_2)`

Plots for model 2

```{r}
draw_graph(model_2)
```


Applying Removal Method

- Model 1 
  
  Refit model 1
  
```{r}
model_1 = lm(log(price) ~ sqft_above + sqft_basement + sqft_living15 + age, data = get_new_data(model_1))
```
  
  
- Model 2 
```{r}
model_2 = lm(log(price) ~ sqft_above + sqft_basement + sqft_living15 + age, data = get_new_data(model_2))
```


Checking With test data, reviewing RMSE and Adjusted R squared between 2 models

```{r}
adj_r2 = c(get_adj_r2(model_1),
                    get_adj_r2(model_2))

RMSE_LOOVE = c(get_loocv_rmse(model_1),
                        get_loocv_rmse(model_2))

result = data.frame(adj_r2,RMSE_LOOVE)
row.names(result) = c("Model1", "Model2")

kable(result)
```

```{r}

```


# Result/ Evaluation - Noah


- Numerical/graphical summary of result
- Comparision of models

# Discussion
- Diagnostic/ Metric of best model
- Commentary/ In depth discussion of best model in context. How is our model be useful


# Discussion
